{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85583a4d-76b2-4f97-88f5-a346f748ef6b",
   "metadata": {},
   "source": [
    "Q1. Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaefe80d-6459-4aeb-9c99-db84d5010b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Course_name  Duration\n",
      "1  Machine Learning         3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "course_name =  [\"Data Science\", \"Machine Learning\", \"Big Data\", \"Data Engineer\"]\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {\"Course_name\" : course_name, \n",
    "                          \"Duration\" :duration})\n",
    "\n",
    "print(df.iloc[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa745e0-1231-4871-9539-1b46e8237e59",
   "metadata": {},
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "755c157c-5245-49d7-8481-0e717b10fe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main difference between loc and iloc in pandas is how they index and select data from a DataFrame:\n",
      "\n",
      "    loc:\n",
      "        Label-based indexing:\n",
      "        It selects data based on the label of the rows and columns.\n",
      "        You can use it to select rows and columns by specifying their labels.\n",
      "        It can also be used for slicing but expects the slice's start and end to be labels, not integer positions.\n",
      "        It can select data based on conditionals, similar to boolean indexing.\n",
      "        It supports selecting rows based on both index labels and boolean conditions, and columns based on column names.\n",
      "        \n",
      "Example:\n",
      "        Select rows with index labels 1 to 3 and columns 'A' and 'B'\n",
      "        df.loc[1:3, ['A', 'B']]\n",
      "        \n",
      "        \n",
      "        \n",
      "    iloc:\n",
      "        Position-based indexing: It selects data based on the integer position of the rows and columns.\n",
      "        You use it to select rows and columns by specifying their integer positions. \n",
      "        It can be used for slicing, and it expects the start and end of the slice to be integer positions.\n",
      "        It does not support boolean indexing directly.\n",
      "        It is used when you need to select rows and columns by their positions in the DataFrame.\n",
      "\n",
      "Example:\n",
      "        Select rows 1 to 3 (excluding 3) and the first two columns\n",
      "        df.iloc[1:3, 0:2]\n",
      "        \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(''' The main difference between loc and iloc in pandas is how they index and select data from a DataFrame:\n",
    "\n",
    "    loc:\n",
    "        Label-based indexing:\n",
    "        It selects data based on the label of the rows and columns.\n",
    "        You can use it to select rows and columns by specifying their labels.\n",
    "        It can also be used for slicing but expects the slice's start and end to be labels, not integer positions.\n",
    "        It can select data based on conditionals, similar to boolean indexing.\n",
    "        It supports selecting rows based on both index labels and boolean conditions, and columns based on column names.\n",
    "        \n",
    "Example:\n",
    "        Select rows with index labels 1 to 3 and columns 'A' and 'B'\n",
    "        df.loc[1:3, ['A', 'B']]\n",
    "        \n",
    "        \n",
    "        \n",
    "    iloc:\n",
    "        Position-based indexing: It selects data based on the integer position of the rows and columns.\n",
    "        You use it to select rows and columns by specifying their integer positions. \n",
    "        It can be used for slicing, and it expects the start and end of the slice to be integer positions.\n",
    "        It does not support boolean indexing directly.\n",
    "        It is used when you need to select rows and columns by their positions in the DataFrame.\n",
    "\n",
    "Example:\n",
    "        Select rows 1 to 3 (excluding 3) and the first two columns\n",
    "        df.iloc[1:3, 0:2]\n",
    "        \n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02045303-1137-4895-aa02-9b2c77b1089c",
   "metadata": {},
   "source": [
    "Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2].\n",
    "\n",
    "Did you observe any difference in both the outputs? If so then explain it.\n",
    "Consider the below code to answer further questions:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4377f453-b468-43ec-af2a-1a26d2bc0fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when accessing elements from the new DataFrame. Since the reindex variable has fewer elements than the DataFrame's index,\n",
      "we'll assume it's a partial reindexing or there was a mistake in the reindex variable provided. For the sake of demonstrating the concept,\n",
      "I'll proceed with the provided reindex variable, assuming a correction to [3, 0, 1, 2] to fit the initial indices [1, 2, 3, 4, 5, 6]. \n",
      "\n",
      "column_1    0.829262\n",
      "column_2    0.036992\n",
      "column_3    0.015589\n",
      "column_4    0.458447\n",
      "column_5    0.435014\n",
      "column_6    0.030315\n",
      "Name: 2, dtype: float64 \n",
      "\n",
      "column_1    0.985569\n",
      "column_2    0.834294\n",
      "column_3    0.394384\n",
      "column_4    0.162235\n",
      "column_5    0.358480\n",
      "column_6    0.525650\n",
      "Name: 1, dtype: float64\n",
      "\n",
      " Now, regarding the difference between .loc[] and .iloc[]:\n",
      "\n",
      "    .loc[] is label-based indexing, which means it accesses rows and columns based on their labels (index names or column names).\n",
      "    .iloc[] is integer position-based indexing, so it accesses rows and columns by their integer positions (starting from 0).\n",
      "\n",
      "Given the reindexing [3, 1, 2, 4]:\n",
      "\n",
      "    new_df.loc[2] will return the row in new_df where the index label is 2. This accesses the data based on the DataFrame's index label.\n",
      "    \n",
      "    new_df.iloc[2] will return the third row in new_df, regardless of its index label, because it's based on the position of \n",
      "    the row within the DataFrame.\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print('''when accessing elements from the new DataFrame. Since the reindex variable has fewer elements than the DataFrame's index,\n",
    "we'll assume it's a partial reindexing or there was a mistake in the reindex variable provided. For the sake of demonstrating the concept,\n",
    "I'll proceed with the provided reindex variable, assuming a correction to [3, 0, 1, 2] to fit the initial indices [1, 2, 3, 4, 5, 6]. \\n''')\n",
    "\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n",
    "new_index = [3,0,1,2]\n",
    "new_df = df1.reindex(new_index)\n",
    "print(new_df.loc[2],\"\\n\")\n",
    "print(new_df.iloc[2])\n",
    "\n",
    "print('''\\n Now, regarding the difference between .loc[] and .iloc[]:\n",
    "\n",
    "    .loc[] is label-based indexing, which means it accesses rows and columns based on their labels (index names or column names).\n",
    "    .iloc[] is integer position-based indexing, so it accesses rows and columns by their integer positions (starting from 0).\n",
    "\n",
    "Given the reindexing [3, 1, 2, 4]:\n",
    "\n",
    "    new_df.loc[2] will return the row in new_df where the index label is 2. This accesses the data based on the DataFrame's index label.\n",
    "    \n",
    "    new_df.iloc[2] will return the third row in new_df, regardless of its index label, because it's based on the position of \n",
    "    the row within the DataFrame.\n",
    "    \n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafe681-98b1-49d0-a9ba-d22afb501686",
   "metadata": {},
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbb3443e-37af-4d0b-a48e-8004c262892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      " column_1    0.772355\n",
      "column_2    0.391795\n",
      "column_3    0.447284\n",
      "column_4    0.416497\n",
      "column_5    0.443719\n",
      "column_6    0.464792\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation of 'column_2': 0.32978047030959134\n"
     ]
    }
   ],
   "source": [
    "column_means = df1.mean()\n",
    "std_dev_column_2 = df1['column_2'].std()\n",
    "print(\"Mean of each column:\\n\", column_means)\n",
    "print(\"\\nStandard Deviation of 'column_2':\", std_dev_column_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41856e81-726d-4c33-90d6-8f2f214646dc",
   "metadata": {},
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18ac40e2-e08e-4b0a-a10d-3b612545f8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unsupported operand type(s) for +: 'float' and 'str' \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985569</td>\n",
       "      <td>0.834294</td>\n",
       "      <td>0.394384</td>\n",
       "      <td>0.162235</td>\n",
       "      <td>0.358480</td>\n",
       "      <td>0.525650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.829262</td>\n",
       "      <td>a string</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.458447</td>\n",
       "      <td>0.435014</td>\n",
       "      <td>0.030315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.033082</td>\n",
       "      <td>0.917132</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>0.378710</td>\n",
       "      <td>0.994622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401760</td>\n",
       "      <td>0.375261</td>\n",
       "      <td>0.709063</td>\n",
       "      <td>0.620845</td>\n",
       "      <td>0.743366</td>\n",
       "      <td>0.666190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.808325</td>\n",
       "      <td>0.696497</td>\n",
       "      <td>0.575671</td>\n",
       "      <td>0.292154</td>\n",
       "      <td>0.558687</td>\n",
       "      <td>0.272139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.815094</td>\n",
       "      <td>0.37464</td>\n",
       "      <td>0.071864</td>\n",
       "      <td>0.116958</td>\n",
       "      <td>0.188059</td>\n",
       "      <td>0.299837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1  column_2  column_3  column_4  column_5  column_6\n",
       "1  0.985569  0.834294  0.394384  0.162235  0.358480  0.525650\n",
       "2  0.829262  a string  0.015589  0.458447  0.435014  0.030315\n",
       "3  0.794118  0.033082  0.917132  0.848341  0.378710  0.994622\n",
       "4  0.401760  0.375261  0.709063  0.620845  0.743366  0.666190\n",
       "5  0.808325  0.696497  0.575671  0.292154  0.558687  0.272139\n",
       "6  0.815094   0.37464  0.071864  0.116958  0.188059  0.299837"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[2, 'column_2'] = \"a string\"\n",
    "try:\n",
    "    column_2_mean = df1['column_2'].mean()\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e,'\\n')\n",
    "df1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84fd7a1f-5728-4d33-8577-97d716a97647",
   "metadata": {},
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dfd73e2-6c53-4f32-bdfb-c41b9345cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Window functions in pandas are powerful tools for performing operations over a specified \"window\" or subset of data. \n",
      "These functions are essential for time series analysis and other applications where you want to perform calculations over a \n",
      "rolling window or need to smooth or aggregate data in some way. The key idea is to apply a function to a subset of data, \n",
      "which \"slides\" across your dataset, allowing you to compute statistics or apply transformations that take into account only\n",
      "a portion of the data at any given time.\n",
      "\n",
      "Types of window functions in pandas include:\n",
      "\n",
      "    Rolling Window Functions: \n",
      "    These functions apply a statistical function to a sliding window of data, defined by a number of periods. \n",
      "    They are useful for smoothing data, calculating moving averages, or computing other rolling statistics. \n",
      "    Example functions include rolling().mean(), rolling().sum(), rolling().std(), etc.\n",
      "\n",
      "    Expanding Window Functions:\n",
      "    Expanding window functions calculate a statistic across a window that expands over time. Unlike rolling windows, \n",
      "    the size of the window increases as you move through the dataset, starting from the beginning of the time series. \n",
      "    Functions include expanding().mean(), expanding().sum(), expanding().std(), among others.\n",
      "\n",
      "    Exponential Weighted (EW) Functions:\n",
      "    These functions apply weights that exponentially decrease over time to the observations, making recent observations have more weight \n",
      "    than older observations. They are particularly useful for time series data where recent data is more relevant. Examples include ewm().\n",
      "    mean(), ewm().std(), etc.\n",
      "\n",
      "    Time-aware Rolling Window: \n",
      "    Similar to rolling window functions but specifically designed for time series data. \n",
      "    These windows take time frequency into consideration, allowing the window size to be specified in terms of time \n",
      "    intervals (e.g., days, hours) rather than a fixed number of observations. This is particularly useful when working with irregular\n",
      "    time series. \n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(''' Window functions in pandas are powerful tools for performing operations over a specified \"window\" or subset of data. \n",
    "These functions are essential for time series analysis and other applications where you want to perform calculations over a \n",
    "rolling window or need to smooth or aggregate data in some way. The key idea is to apply a function to a subset of data, \n",
    "which \"slides\" across your dataset, allowing you to compute statistics or apply transformations that take into account only\n",
    "a portion of the data at any given time.\n",
    "\n",
    "Types of window functions in pandas include:\n",
    "\n",
    "    Rolling Window Functions: \n",
    "    These functions apply a statistical function to a sliding window of data, defined by a number of periods. \n",
    "    They are useful for smoothing data, calculating moving averages, or computing other rolling statistics. \n",
    "    Example functions include rolling().mean(), rolling().sum(), rolling().std(), etc.\n",
    "\n",
    "    Expanding Window Functions:\n",
    "    Expanding window functions calculate a statistic across a window that expands over time. Unlike rolling windows, \n",
    "    the size of the window increases as you move through the dataset, starting from the beginning of the time series. \n",
    "    Functions include expanding().mean(), expanding().sum(), expanding().std(), among others.\n",
    "\n",
    "    Exponential Weighted (EW) Functions:\n",
    "    These functions apply weights that exponentially decrease over time to the observations, making recent observations have more weight \n",
    "    than older observations. They are particularly useful for time series data where recent data is more relevant. Examples include ewm().\n",
    "    mean(), ewm().std(), etc.\n",
    "\n",
    "    Time-aware Rolling Window: \n",
    "    Similar to rolling window functions but specifically designed for time series data. \n",
    "    These windows take time frequency into consideration, allowing the window size to be specified in terms of time \n",
    "    intervals (e.g., days, hours) rather than a fixed number of observations. This is particularly useful when working with irregular\n",
    "    time series. \n",
    "    \n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1140325-b07d-45e7-8d55-9fc90020f617",
   "metadata": {},
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "[Hint: Use pandas.datetime function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f398748d-3c39-48d4-b7c0-ab24c7b7e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 2024\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current_datetime = datetime.now()\n",
    "formatted_date = current_datetime.strftime('%B %Y')\n",
    "print(formatted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5288a-2078-4fd6-bdc3-5aa75ad263da",
   "metadata": {},
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5be03c7-4bbe-4fe2-baf0-0f45313871ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  2003-10-12\n",
      "Enter the second date (YYYY-MM-DD):  2024-9-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference is 7641 days, 0 hours, and 0 minutes.\n"
     ]
    }
   ],
   "source": [
    "def calculate_time_difference(date1, date2):\n",
    "    datetime1 = pd.to_datetime(date1)\n",
    "    datetime2 = pd.to_datetime(date2)\n",
    "    timedelta = datetime2 - datetime1\n",
    "    days = timedelta.days\n",
    "    hours, remainder = divmod(timedelta.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    return days, hours, minutes\n",
    "date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "days, hours, minutes = calculate_time_difference(date1, date2)\n",
    "print(f\"The difference is {days} days, {hours} hours, and {minutes} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870e7aa-d947-44d8-a18b-8374a1b8e4ca",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f4473-12eb-4531-b136-da02380ef31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_to_categorical_and_sort(filepath, column_name, category_order):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "    sorted_df = df.sort_values(by=column_name)\n",
    "    \n",
    "    return sorted_df\n",
    "filepath = input(\"Enter the file path of the CSV: \")\n",
    "column_name = input(\"Enter the column name to convert to categorical type: \")\n",
    "category_order = input(\"Enter the category order, separated by commas (e.g., cat1,cat2,cat3): \").split(',')\n",
    "sorted_df = convert_column_to_categorical_and_sort(filepath, column_name, category_order)\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5aa6a9-6c43-4958-8b74-df426759eef6",
   "metadata": {},
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973480c5-7a39-40a8-ac02-a74ea3a88c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sales_data(filepath):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Assuming the CSV has columns 'Date', 'Category', and 'Sales'\n",
    "    # Pivot the DataFrame to get a sum of sales for each category by date\n",
    "    sales_pivot = df.pivot_table(index='Date', columns='Category', values='Sales', aggfunc='sum')\n",
    "    \n",
    "    # Plot a stacked bar chart\n",
    "    sales_pivot.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    plt.title('Sales of Product Categories Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.legend(title='Category')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Display the chart\n",
    "    plt.show()\n",
    "\n",
    "# Prompt the user for the file path\n",
    "filepath = input(\"Enter the file path of the CSV: \")\n",
    "\n",
    "# Plot the sales data\n",
    "plot_sales_data(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053d774-8510-44ea-a199-bfdb7b23485f",
   "metadata": {},
   "source": [
    "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table.\n",
    "The program should do the followingM\n",
    "I Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    "I Read the CSV file into a Pandas DataFrameR\n",
    "I Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    "I Display the mean, median, and mode in a table.\n",
    "Assume the CSV file contains the following columnsM\n",
    "I Student ID: The ID of the studentR\n",
    "I Test Score: The score of the student's test.\n",
    "Example usage of the program:\n",
    "Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "+-----------+--------+\n",
    "| Statistic | Value |\n",
    "+-----------+--------+\n",
    "| Mean | 79.6 |\n",
    "| Median | 82 |\n",
    "| Mode | 85, 90 |\n",
    "+-----------+--------+\n",
    "Assume that the CSV file student_data.csv contains the following data:\n",
    "Student ID,Test Score\n",
    "1,85\n",
    "2,90\n",
    "3,80\n",
    "4,75\n",
    "5,85\n",
    "6,82\n",
    "7,78\n",
    "8,85\n",
    "9,90\n",
    "10,85\n",
    "The program should calculate the mean, median, and mode of the test scores and display the results\n",
    "in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3766af07-1f59-4e6d-8166-4ad55c9a9eac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtabulate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tabulate\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Score\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m85\u001b[39m, \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m85\u001b[39m, \u001b[38;5;241m82\u001b[39m, \u001b[38;5;241m78\u001b[39m, \u001b[38;5;241m85\u001b[39m, \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m85\u001b[39m]\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "data = {\n",
    "    \"Student ID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"Test Score\": [85, 90, 80, 75, 85, 82, 78, 85, 90, 85]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"student_data.csv\", index=False)\n",
    "\n",
    "def calculate_statistics(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    mean_score = df['Test Score'].mean()\n",
    "    median_score = df['Test Score'].median()\n",
    "    mode_score = df['Test Score'].mode().tolist()\n",
    "    statistics = [\n",
    "        [\"Mean\", mean_score],\n",
    "        [\"Median\", median_score],\n",
    "        [\"Mode\", ', '.join(map(str, mode_score))] \n",
    "    ]\n",
    "    print(tabulate(statistics, headers=[\"Statistic\", \"Value\"], tablefmt=\"grid\"))\n",
    "filepath = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "calculate_statistics(\"student_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77083e50-8665-4ed4-af6e-3d997ef37168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c32f1-678f-48a9-878f-3788753ed7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
